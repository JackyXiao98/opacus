================================================================================
DPSGD ACCURACY/CONSISTENCY TEST - USAGE GUIDE
================================================================================

OVERVIEW:
---------
The accuracy test verifies that different DPSGD implementations (ghost_fsdp,
flash_fsdp, flash_fsdp_fuse, etc.) produce consistent results. This is done
by running with minimal privacy (epsilon≈1e-3, max_grad_norm=10000) so that
all algorithms should produce nearly identical loss and gradient values.


KEY PARAMETERS:
---------------
- epsilon ≈ 1e-3 (sigma = 0.01): Very low noise, minimal privacy
- max_grad_norm = 10000: Very high clip norm, essentially no clipping
- random_seed = 42: Fixed seed for reproducibility across all modes


WHAT IS MEASURED:
-----------------
1. Loss trajectory: Loss value at each training iteration
2. Gradient norms: Total gradient norm before optimizer step
3. Linear layer norms: Weight and gradient norms for linear layers
   (measured at first and last iteration to save computation)


RUNNING THE TESTS:
------------------

Option 1: Full Accuracy Test (comprehensive)
   export HF_TOKEN=your_huggingface_token
   ./run_accuracy_test.sh
   
   This tests all FSDP modes:
   - no_dp (baseline)
   - ghost_fsdp
   - flash_fsdp
   - flash_fsdp_bk
   - flash_fsdp_fuse
   - flash_fsdp_fuse_bk

Option 2: Quick Accuracy Test (faster)
   export HF_TOKEN=your_huggingface_token
   ./quick_accuracy_test.sh
   
   This tests only key modes:
   - no_dp
   - flash_fsdp
   - flash_fsdp_fuse

Option 3: Enable Accuracy Mode in Main Script
   Edit run_all_experiments.sh and set:
   ACCURACY_TEST_MODE=true
   
   Then run normally:
   ./run_all_experiments.sh
   
   This runs the regular profiling with accuracy test logging enabled.

Option 4: Single Experiment with Accuracy Test
   python single_experiment.py \
       --mode flash_fsdp_fuse \
       --seq-length 1024 \
       --batch-size 2 \
       --num-iter 5 \
       --sigma 0.01 \
       --max-grad-norm 10000 \
       --accuracy-test \
       --random-seed 42 \
       --output results.json \
       --model-name meta-llama/Llama-3.2-1B \
       --token $HF_TOKEN


OUTPUT FILES:
-------------
1. JSON files: Detailed results for each mode
   - Contains: loss_values, final_loss, grad_norms, avg_grad_norm,
              layer_norms_history (if accuracy test enabled)

2. Summary text file: Comparison table
   - Shows final loss, avg gradient norm for all modes
   - Includes consistency metrics (mean, std dev, max diff)

3. Visualization plots (when using visualize_results.py):
   - loss_trajectory.png: Loss over iterations for all modes
   - gradient_norm_comparison.png: Gradient norms over iterations
   - final_loss_comparison.png: Bar chart of final losses


INTERPRETING RESULTS:
---------------------
Good Consistency:
  - Loss values differ by < 1e-4
  - Gradient norms differ by < 1e-3
  - All modes converge to similar final loss

Potential Issues:
  - Large differences (> 1%) indicate implementation bugs
  - Diverging trajectories suggest algorithmic differences
  - NaN values indicate numerical instability


EXAMPLE RESULTS:
----------------
Mode                     Final Loss       Avg Grad Norm
------------------------------------------------------------------------
Non-DP FSDP2            1.234567         12.345678
Ghost FSDP              1.234568         12.345679
Flash FSDP              1.234567         12.345677
Flash FSDP (Fuse)       1.234568         12.345678
------------------------------------------------------------------------

CONSISTENCY ANALYSIS:
  Final Loss - Mean: 1.234567, Std: 0.000001, Max Diff: 0.000002
  Avg Grad Norm - Mean: 12.345678, Std: 0.000001, Max Diff: 0.000002


TROUBLESHOOTING:
----------------
1. Out of Memory (OOM):
   - Reduce batch size: --batch-size 1
   - Use smaller model: meta-llama/Llama-3.2-1B
   - Reduce sequence length: --seq-length 512

2. Different Results Across Modes:
   - Verify same random seed is used
   - Check that sigma and max_grad_norm are consistent
   - Ensure same model initialization

3. HuggingFace Token Issues:
   - Verify token: echo $HF_TOKEN
   - Generate token at: https://huggingface.co/settings/tokens
   - Ensure model access is granted


TECHNICAL NOTES:
----------------
- All experiments use the same random seed to ensure identical initialization
- Synthetic data is generated deterministically based on rank and seed
- FSDP modes use bfloat16 for parameters, float32 for reductions
- Layer norms are only computed at iteration 0 and last iteration to save time
- Full tensor materialization is used for norm computation (handles DTensor)


CUSTOMIZATION:
--------------
To modify test parameters, edit run_accuracy_test.sh:
  - SIGMA: Noise multiplier (lower = less noise)
  - MAX_GRAD_NORM: Clipping threshold (higher = less clipping)
  - NUM_ITER: Number of training iterations
  - RANDOM_SEED: Seed for reproducibility
  - MODEL_NAME: Which model to test
  - SEQ_LENGTH: Sequence length
  - BATCH_SIZE: Batch size per GPU


RELATED FILES:
--------------
- single_experiment.py: Core experiment runner
- run_accuracy_test.sh: Full accuracy test suite
- quick_accuracy_test.sh: Quick 3-mode test
- run_all_experiments.sh: Main profiling script (with accuracy mode option)
- visualize_results.py: Generate plots and summaries


REFERENCES:
-----------
For more information on the DPSGD implementations:
  - opacus/grad_sample/grad_sample_module_fast_gradient_clipping_fsdp_fuse.py
  - opacus/grad_sample/fused_flash_linear.py
  - FUSED_FLASH_LINEAR_OPTIMIZATION.md

================================================================================

